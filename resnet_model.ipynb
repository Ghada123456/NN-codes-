{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "xXNrVDTFNqcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "_BATCH_NORM_DECAY = 0.997\n",
        "_BATCH_NORM_EPSILON = 1e-5\n",
        "DEFAULT_VERSION = 2\n",
        "DEFAULT_DTYPE = tf.float32\n",
        "CASTABLE_TYPES = (tf.float16,)\n",
        "ALLOWED_TYPES = (DEFAULT_DTYPE,) + CASTABLE_TYPES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Get94rFNv9M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batch_norm(inputs, training, data_format):\n",
        " \n",
        "  return tf.compat.v1.layers.batch_normalization(\n",
        "      inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n",
        "      momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,\n",
        "      scale=True, training=training, fused=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "91wzvE8iOB1-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fixed_padding(inputs, kernel_size, data_format):\n",
        "  \n",
        "  pad_total = kernel_size - 1\n",
        "  pad_beg = pad_total // 2\n",
        "  pad_end = pad_total - pad_beg\n",
        "\n",
        "  if data_format == 'channels_first':\n",
        "    padded_inputs = tf.pad(tensor=inputs,\n",
        "                           paddings=[[0, 0], [0, 0], [pad_beg, pad_end],\n",
        "                                     [pad_beg, pad_end]])\n",
        "  else:\n",
        "    padded_inputs = tf.pad(tensor=inputs,\n",
        "                           paddings=[[0, 0], [pad_beg, pad_end],\n",
        "                                     [pad_beg, pad_end], [0, 0]])\n",
        "  return padded_inputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AU9ebky5OG5a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d_fixed_padding(inputs, filters, kernel_size, strides, data_format):\n",
        "\n",
        "  if strides > 1:\n",
        "    inputs = fixed_padding(inputs, kernel_size, data_format)\n",
        "\n",
        "  return tf.compat.v1.layers.conv2d(\n",
        "      inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides,\n",
        "      padding=('SAME' if strides == 1 else 'VALID'), use_bias=False,\n",
        "      kernel_initializer=tf.compat.v1.variance_scaling_initializer(),\n",
        "      data_format=data_format)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uz6qq7b6OKj5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _building_block_v1(inputs, filters, training, projection_shortcut, strides,\n",
        "                       data_format):\n",
        "\n",
        "  shortcut = inputs\n",
        "\n",
        "  if projection_shortcut is not None:\n",
        "    shortcut = projection_shortcut(inputs)\n",
        "    shortcut = batch_norm(inputs=shortcut, training=training,\n",
        "                          data_format=data_format)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
        "      data_format=data_format)\n",
        "  inputs = batch_norm(inputs, training, data_format)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=1,\n",
        "      data_format=data_format)\n",
        "  inputs = batch_norm(inputs, training, data_format)\n",
        "  inputs += shortcut\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hSwxYdmgOO8a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _building_block_v2(inputs, filters, training, projection_shortcut, strides,\n",
        "                       data_format):\n",
        "\n",
        "  shortcut = inputs\n",
        "  inputs = batch_norm(inputs, training, data_format)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "\n",
        "  if projection_shortcut is not None:\n",
        "    shortcut = projection_shortcut(inputs)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
        "      data_format=data_format)\n",
        "\n",
        "  inputs = batch_norm(inputs, training, data_format)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=1,\n",
        "      data_format=data_format)\n",
        "\n",
        "  return inputs + shortcut"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "foXqJZ8YOT_D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _bottleneck_block_v1(inputs, filters, training, projection_shortcut,\n",
        "                         strides, data_format):\n",
        "\n",
        "  shortcut = inputs\n",
        "\n",
        "  if projection_shortcut is not None:\n",
        "    shortcut = projection_shortcut(inputs)\n",
        "    shortcut = batch_norm(inputs=shortcut, training=training,\n",
        "                          data_format=data_format)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=1, strides=1,\n",
        "      data_format=data_format)\n",
        "  inputs = batch_norm(inputs, training, data_format)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
        "      data_format=data_format)\n",
        "  inputs = batch_norm(inputs, training, data_format)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,\n",
        "      data_format=data_format)\n",
        "  inputs = batch_norm(inputs, training, data_format)\n",
        "  inputs += shortcut\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  return inputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SiqNi76ZOeoa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _bottleneck_block_v2(inputs, filters, training, projection_shortcut,\n",
        "                         strides, data_format):\n",
        "\n",
        "  shortcut = inputs\n",
        "  inputs = batch_norm(inputs, training, data_format)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "\n",
        "  if projection_shortcut is not None:\n",
        "    shortcut = projection_shortcut(inputs)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=1, strides=1,\n",
        "      data_format=data_format)\n",
        "\n",
        "  inputs = batch_norm(inputs, training, data_format)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
        "      data_format=data_format)\n",
        "\n",
        "  inputs = batch_norm(inputs, training, data_format)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,\n",
        "      data_format=data_format)\n",
        "\n",
        "  return inputs + shortcut"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQTusrlLOkyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def block_layer(inputs, filters, bottleneck, block_fn, blocks, strides,\n",
        "                training, name, data_format):\n",
        "\n",
        "  filters_out = filters * 4 if bottleneck else filters\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YjD2FM89OpvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "08eb037b-ff07-4ca1-f5eb-9bef363e19db"
      },
      "cell_type": "code",
      "source": [
        "def projection_shortcut(inputs):\n",
        "    return conv2d_fixed_padding(\n",
        "        inputs=inputs, filters=filters_out, kernel_size=1, strides=strides,\n",
        "        data_format=data_format)\n",
        "\n",
        "  \n",
        "  inputs = block_fn(inputs, filters, training, projection_shortcut, strides,\n",
        "                    data_format)\n",
        "\n",
        "  for _ in range(1, blocks):\n",
        "    inputs = block_fn(inputs, filters, training, None, 1, data_format)\n",
        "\n",
        "  return tf.identity(inputs, name)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-44f153718262>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    inputs = block_fn(inputs, filters, training, projection_shortcut, strides,\u001b[0m\n\u001b[0m                                                                              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7FeCXiNoOwS-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(object):\n",
        "  \"\"\"Base class for building the Resnet Model.\"\"\"\n",
        "\n",
        "  def __init__(self, resnet_size, bottleneck, num_classes, num_filters,\n",
        "               kernel_size,\n",
        "               conv_stride, first_pool_size, first_pool_stride,\n",
        "               block_sizes, block_strides,\n",
        "               resnet_version=DEFAULT_VERSION, data_format=None,\n",
        "               dtype=DEFAULT_DTYPE):\n",
        "\n",
        "    self.resnet_size = resnet_size\n",
        "\n",
        "    if not data_format:\n",
        "      data_format = (\n",
        "          'channels_first' if tf.test.is_built_with_cuda() else 'channels_last')\n",
        "\n",
        "    self.resnet_version = resnet_version\n",
        "    if resnet_version not in (1, 2):\n",
        "      raise ValueError(\n",
        "          'Resnet version should be 1 or 2. See README for citations.')\n",
        "\n",
        "    self.bottleneck = bottleneck\n",
        "    if bottleneck:\n",
        "      if resnet_version == 1:\n",
        "        self.block_fn = _bottleneck_block_v1\n",
        "      else:\n",
        "        self.block_fn = _bottleneck_block_v2\n",
        "    else:\n",
        "      if resnet_version == 1:\n",
        "        self.block_fn = _building_block_v1\n",
        "      else:\n",
        "        self.block_fn = _building_block_v2\n",
        "\n",
        "    if dtype not in ALLOWED_TYPES:\n",
        "      raise ValueError('dtype must be one of: {}'.format(ALLOWED_TYPES))\n",
        "\n",
        "    self.data_format = data_format\n",
        "    self.num_classes = num_classes\n",
        "    self.num_filters = num_filters\n",
        "    self.kernel_size = kernel_size\n",
        "    self.conv_stride = conv_stride\n",
        "    self.first_pool_size = first_pool_size\n",
        "    self.first_pool_stride = first_pool_stride\n",
        "    self.block_sizes = block_sizes\n",
        "    self.block_strides = block_strides\n",
        "    self.dtype = dtype\n",
        "    self.pre_activation = resnet_version == 2\n",
        "\n",
        "  def _custom_dtype_getter(self, getter, name, shape=None, dtype=DEFAULT_DTYPE,\n",
        "                           *args, **kwargs):\n",
        "    \n",
        "   \n",
        "\n",
        "    if dtype in CASTABLE_TYPES:\n",
        "      var = getter(name, shape, tf.float32, *args, **kwargs)\n",
        "      return tf.cast(var, dtype=dtype, name=name + '_cast')\n",
        "    else:\n",
        "      return getter(name, shape, dtype, *args, **kwargs)\n",
        "\n",
        "  def _model_variable_scope(self):\n",
        "    \"\"\"Returns a variable scope that the model should be created under.\n",
        "    If self.dtype is a castable type, model variable will be created in fp32\n",
        "    then cast to self.dtype before being used.\n",
        "    Returns:\n",
        "      A variable scope for the model.\n",
        "    \"\"\"\n",
        "\n",
        "    return tf.compat.v1.variable_scope('resnet_model',\n",
        "                                       custom_getter=self._custom_dtype_getter)\n",
        "\n",
        "  def __call__(self, inputs, training):\n",
        "   \n",
        "\n",
        "    with self._model_variable_scope():\n",
        "      if self.data_format == 'channels_first':\n",
        "       \n",
        "        inputs = tf.transpose(a=inputs, perm=[0, 3, 1, 2])\n",
        "\n",
        "      inputs = conv2d_fixed_padding(\n",
        "          inputs=inputs, filters=self.num_filters, kernel_size=self.kernel_size,\n",
        "          strides=self.conv_stride, data_format=self.data_format)\n",
        "      inputs = tf.identity(inputs, 'initial_conv')\n",
        "\n",
        "    \n",
        "      if self.resnet_version == 1:\n",
        "        inputs = batch_norm(inputs, training, self.data_format)\n",
        "        inputs = tf.nn.relu(inputs)\n",
        "\n",
        "      if self.first_pool_size:\n",
        "        inputs = tf.compat.v1.layers.max_pooling2d(\n",
        "            inputs=inputs, pool_size=self.first_pool_size,\n",
        "            strides=self.first_pool_stride, padding='SAME',\n",
        "            data_format=self.data_format)\n",
        "        inputs = tf.identity(inputs, 'initial_max_pool')\n",
        "\n",
        "      for i, num_blocks in enumerate(self.block_sizes):\n",
        "        num_filters = self.num_filters * (2**i)\n",
        "        inputs = block_layer(\n",
        "            inputs=inputs, filters=num_filters, bottleneck=self.bottleneck,\n",
        "            block_fn=self.block_fn, blocks=num_blocks,\n",
        "            strides=self.block_strides[i], training=training,\n",
        "            name='block_layer{}'.format(i + 1), data_format=self.data_format)\n",
        "\n",
        "     \n",
        "      if self.pre_activation:\n",
        "        inputs = batch_norm(inputs, training, self.data_format)\n",
        "        inputs = tf.nn.relu(inputs)\n",
        "\n",
        "     \n",
        "      axes = [2, 3] if self.data_format == 'channels_first' else [1, 2]\n",
        "      inputs = tf.reduce_mean(input_tensor=inputs, axis=axes, keepdims=True)\n",
        "      inputs = tf.identity(inputs, 'final_reduce_mean')\n",
        "\n",
        "      inputs = tf.squeeze(inputs, axes)\n",
        "      inputs = tf.compat.v1.layers.dense(inputs=inputs, units=self.num_classes)\n",
        "      inputs = tf.identity(inputs, 'final_dense')\n",
        "      return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eHA6aVAYPPB0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}